---
layout: post
title: "Quibs: My Early Attempt at Genetic Learning"
author: "Tyler Sengia"
categories: simulation, code, ai/ml
tags: [javascript, ml, genetic-learning]
image: quibs-screenshot.png
---

A long time ago, I decided to make my own simulation to see if "virtual organisms" would be able to learn to survive in a simulated habitat. These virtual organisms were named "Quibs." I don't know why I chose that name; probably because it just sounded funny.  

You can run this simulation in your own browser by going to [this page on my website](assets/static/quibs.html). The simulation is entirely programmed in JavaScript and is rendered in real time on an HTML5 Canvas element.  

<div class="note" >
  Link to demo application: <a href="assets/static/quibs.html" >quibs.html</a>
</div>

# Simulation Environment
The virtual environment is made up of two objects:  
- "Quibs" - The virtual organisms that wander around. They are red squares numbered with white text.  
- "Food" - The smaller light blue squares that are stationary.  

For each "tick" of the simulation, a forward pass of each Quib's neural network is evaluated to determine the direction that the Quib moves. If a Quib goes off the screen, it is immediately wraps around to the opposite edge. Additionally, after movement, each Quib uses up some of its energy. You can see the remaining amount of energy that each Quib has on the colored chart on the lower right corner of the simulation screen. 

When a Quib runs out of energy, it dies and a Food object is spawned in its place.  

The simulation continues until only 3 Quibs are remaining, which are then "bred" to create the next generation of Quibs for the next round of the simulation. Rarely, the remaining Quibs die off at the same exact time, and when that happens, the last surviving Quib is duplicated until there are three Quibs to be used for breeding. When the next round starts, the new Quibs are placed at random locations, but the Food objects remain.  

# Quib Feedforward Neural Network
The Quib's decision making is powered through a simple feed-forward artificial neural network shown below:  

<div style="text-align: center;" >
<img src="assets/img/quibs-network.png" alt="Diagram of the quib's feedforward neural network" />  
</div>

The neural network is comprised of 4 input neurons, 5 hidden neurons, and 4 output neurons. 
This gives a total of 40 weights, and no bias neurons/inputs are used. 
The 4 input neurons are fed either a 1 or a 0 if the nearest food object is to the right, left, above, or below them. Each input neuron is assigned a direction: left, right, up, or down.  

Each output neuron is given a direction as well: left, right, up, or down. The direction that the Quib moves in is based upon comparing left versus right and up versus down. This means that a Quib can move both horizontally and vertically in one tick. The amount the Quib moves is based upon the magnitude of the output neuron.  

# Training
For the first round of the generation, all Quibs are created with randomly generated weights. 
At the end of a round, the 3 surviving Quibs are then "bred" to create the next generation of Quibs. 
Every Quib in the next generation "inherits" network weights from its parents from the previous generation.

Below is a table describing all of the different "inheritance" methods used to generate the weights for the next generation of Quibs.

| Inheritance Method | Description |
| -----------------:|:----------- |
| Clone             | Each weight is copied exactly from a parent Quib |
| Random            | Each weight is random |
| Random Mix        | Each weight is randomly chosen to either be copied from a parent Quib, or take on a random value |
| Merge             | Each weight is randomly copied from one of two parent Quibs |
| Sum               | Each weight is a sum of the parent's value for that weight |
| Average           | Each weight is the average of the parent's value for that weight |

Below is a list of each Quib # and how it was generated:  

| Quib # | Inheritance Method | Parent(s)|
| ------:| ----------------- |:-------- |
|      0 | Clone             | "Alpha" Quib |
|      1 | Clone             | "Beta" Quib |
|      2 | Clone             | "C" Quib |
|      3 | Random Mix        | "Alpha" Quib |
|      4 | Random Mix        | "Beta" Quib |
|      5 | Random Mix        | "C" Quib |
|      6 | Merge             | Alpha and Beta Quibs |
|      7 | Merge             | Beta and C Quibs |
|      8 | Merge             | Alpha and C Quibs |
|      9 | Sum               | Alpha, Beta, and C Quibs |
|     10 | Average           | Alpha, Beta, and C Quibs |

## Conclusions
I have not run any tests/investigations on which breeding method is most effective.  

All I know is that after a few minutes of observing these virtual creatures, you may start to see some "intelligent" movement patterns. The table below lists some common behavioural patterns I've seen arise:

| Behaviour | Description |
| -----------------:|:----------- |
| Floater             | Regardless of where the Food objects are, the Quib will move in one direction with constant velocity. |
| Stuck            | Quib gets stuck at an equilibrium point between two food objects. |
| Zig Zag        | Quib will move directly towards the closest food object, and zig zags towards the food until it eats the food. |
| Zig Zag Bounce             | Similar to the above Zig Zag pattern, but has a slight defect that causes the Quib to "bounce" away from the closest food object when it gets close. |

Out of the above behavioural patterns, the Floaters and the Zig Zags seem to be the most "optimal"/"intelligent" behaviors.  Quibs that bounce or get stuck seem to get less food.  

Zig Zagging Quibs seem the most "intelligent" since they move directly to the nearest food objects, however the Floaters are still a valid strategy! The Floaters simply move in one direction, and they move *fast*. This allows Floaters to rely on pure luck to run into food objects, which is more likely the faster they go.  

It's almost like a safari, I hope you enjoy watching them! 