---
layout: post
title: "Quibs: My Early Attempt at Genetic Learning"
author: "Tyler Sengia"
categories: simulation, code, ai/ml
tags: [javascript, ml, genetic-learning]
image: quibs-screenshot.png
---

<div class="note" >
  Link to demo application: <a href="assets/static/quibs.html" ><pre>quibs.html</pre></a>
</div>

Way back when I was a kiddo in the 7th grade, I decided to make my own game to see if "virtual organisms" would be able to learn to survive in a simulated habitat. These "virtual organisms" were named "Quibs." I don't know why I chose that name; probably because it just sounded funny.  

You can run this simulation in your own browser by going to [this page on my website](assets/static/quibs.html). The simulation was entirely programmed in JavaScript and the simulated environment was rendered in real time on an HTML5 Canvas element.  

# Simulation Environment
The virtual environment that is made up of two objects:  
- "Quibs" - The red squares that wander around. They are numbered with white text.  
- "Food" - The smaller light blue squares that stay put.  

For each "tick" of the simulation, every Quib uses up some of its "energy". You can see the remaining amount of energy that each Quib has on the colored chart on the lower right corner of the simulation screen. When a Quib runs out of energy, it dies and is eliminated from the simulation. 

When a Quib runs out of energy and dies, it also leaves behind a Food object at the same location it died.  

The simulation continues until all the Quibs die but 3 of them, which are then "bred" to create the next generation of Quibs for the next round of the simulation. Rarely the remaining Quibs die off at the same exact time, so when that happens, the last surviving Quib is simply cloned until there are three Quibs to be used for breeding.  

When the next round starts, the new Quibs are placed at random, but the Food objects remain.  

Each tick, a forward pass of each Quib's neural network is evaluated to determine the direction that the Quib moves.  

When a Quib goes off the screen, it is immediatly "teleported" to the opposite edge (like it wrapped around).

# Quib Feedforward Neural Network
The Quib's decision making is powered through a simple feed-forward artificial neural network shown below:  

<div style="text-align: center;" >
<img src="assets/img/quibs-network.png" alt="Diagram of the quib's feedforward neural network" />  
</div>

The neural network is comprised of 4 input neurons, 5 hidden neurons, and 4 output neurons. 

This gives a total of 40 weights, and no bias neurons/inputs are used.  
The 4 input neurons are fed either a 1 or a 0 (boolean) if the nearest food object is to the right, left, above, or below them. Each input neuron is assigned a direction (left, right, up, down).  

Each output neuron is given a direction as well (left, right, up, down). If the left output has a higher value than the right output, then the `moveLeft()` function is called (the same goes for the other directions).  


# Training/Breeding
As mentioned before, at the end of the round the 3 surviving Quibs are then "bred" to create the next generation of Quibs.  
This "breeding" is simply a mixing and mashing of the neural network weights.  
For the very first round of the generation, all Quibs are created by randomly generated weights.  

Below is a table describing all of the different training/"breeding" methods used to generate the weights for the next generation of Quibs.

| Training Method | Description |
| -----------------:|:----------- |
| Clone             | Each weight is copied exactly from a parent Quib |
| Random            | Each weight is random |
| Random Mix        | Each weight is randomly chosen to either be copied from a parent Quib, or take on a random value |
| Merge             | Each weight is randomly copied from one of two parent Quibs |
| Sum               | Each weight is a sum of the parent's value for that weight |
| Average           | Each weight is the average of the parent's value for that weight |

Below is a list of each Quib # and how it was generated:  

| Quib # | Training Method | Parent(s)|
| ------:| ----------------- |:-------- |
|      0 | Clone             | "Alpha" Quib |
|      1 | Clone             | "Beta" Quib |
|      2 | Clone             | "C" Quib |
|      3 | Random Mix        | "Alpha" Quib |
|      4 | Random Mix        | "Beta" Quib |
|      5 | Random Mix        | "C" Quib |
|      6 | Merge             | Alpha and Beta Quibs |
|      7 | Merge             | Beta and C Quibs |
|      8 | Merge             | Alpha and C Quibs |
|      9 | Sum               | Alpha, Beta, and C Quibs |
|     10 | Average           | Alpha, Beta, and C Quibs |

## Conclusions
I have not run any tests/investigations on which breeding method is most effective.
All I know is that after a few minutes of observing these virtual creatures, you may start to see "intelligent" movement patterns. Quibs that "zig zag" towards a Food object seem to fare better, almost as if they home in on the Food.  

There are Quibs that exhibit other movement patterns.   
Some are "floaters" that constantly move in one direction across the screen (which is sometimes just as effective as zig zags).  
Some get stuck between two or three Food objects. Some will zig zag towards a Food object to their left, but will not respond to a food object on its right! 

It's almost like a safari, enjoy watching them! 
